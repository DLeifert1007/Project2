{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4957b22c-5bd9-4433-8b73-c7b4d85332ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b978b6e7-ff86-442e-b450-cadc6c55c8e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Energy Consumption</th>\n",
       "      <th>Carbon Emissions</th>\n",
       "      <th>Waste Generation</th>\n",
       "      <th>Community Engagement</th>\n",
       "      <th>Volunteer Participation</th>\n",
       "      <th>Health Impact</th>\n",
       "      <th>Water Usage</th>\n",
       "      <th>Material Recycling Rate</th>\n",
       "      <th>Operational Cost Efficiency</th>\n",
       "      <th>Event Scale</th>\n",
       "      <th>Event Focus</th>\n",
       "      <th>Sustainability Score</th>\n",
       "      <th>Social Impact Level</th>\n",
       "      <th>Resource Efficiency</th>\n",
       "      <th>Event Type Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Moderate</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>Moderate Engagement</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate Impact</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>High Efficiency</td>\n",
       "      <td>Local</td>\n",
       "      <td>Community Development</td>\n",
       "      <td>Low</td>\n",
       "      <td>High Engagement</td>\n",
       "      <td>Moderate Efficiency</td>\n",
       "      <td>Health-Oriented</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>High</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>High</td>\n",
       "      <td>Moderate Engagement</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low Impact</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Low</td>\n",
       "      <td>Moderate Efficiency</td>\n",
       "      <td>National</td>\n",
       "      <td>Community Development</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Low Engagement</td>\n",
       "      <td>Moderate Efficiency</td>\n",
       "      <td>Recreational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>Low Engagement</td>\n",
       "      <td>High</td>\n",
       "      <td>Moderate Impact</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate Efficiency</td>\n",
       "      <td>National</td>\n",
       "      <td>Community Development</td>\n",
       "      <td>High</td>\n",
       "      <td>Low Engagement</td>\n",
       "      <td>High Efficiency</td>\n",
       "      <td>Recreational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>Moderate Engagement</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate Impact</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate Efficiency</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Community Development</td>\n",
       "      <td>High</td>\n",
       "      <td>Low Engagement</td>\n",
       "      <td>High Efficiency</td>\n",
       "      <td>Recreational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Moderate</td>\n",
       "      <td>High</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low Engagement</td>\n",
       "      <td>Low</td>\n",
       "      <td>Moderate Impact</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>High Efficiency</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Community Development</td>\n",
       "      <td>Low</td>\n",
       "      <td>Moderate Engagement</td>\n",
       "      <td>Moderate Efficiency</td>\n",
       "      <td>Community Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>High</td>\n",
       "      <td>Moderate Engagement</td>\n",
       "      <td>High</td>\n",
       "      <td>Low Impact</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Low</td>\n",
       "      <td>Moderate Efficiency</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Community Development</td>\n",
       "      <td>High</td>\n",
       "      <td>Low Engagement</td>\n",
       "      <td>Moderate Efficiency</td>\n",
       "      <td>Community Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Low</td>\n",
       "      <td>High</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate Engagement</td>\n",
       "      <td>Low</td>\n",
       "      <td>Moderate Impact</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>High Efficiency</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Youth-Focused</td>\n",
       "      <td>High</td>\n",
       "      <td>Moderate Engagement</td>\n",
       "      <td>Moderate Efficiency</td>\n",
       "      <td>Youth-Focused</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>High Engagement</td>\n",
       "      <td>Low</td>\n",
       "      <td>High Impact</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>High Efficiency</td>\n",
       "      <td>National</td>\n",
       "      <td>Community Development</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>High Engagement</td>\n",
       "      <td>Low Efficiency</td>\n",
       "      <td>Recreational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>High Engagement</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>High Impact</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>Moderate Efficiency</td>\n",
       "      <td>Local</td>\n",
       "      <td>Community Development</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Low Engagement</td>\n",
       "      <td>Low Efficiency</td>\n",
       "      <td>Youth-Focused</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>Moderate Engagement</td>\n",
       "      <td>High</td>\n",
       "      <td>Moderate Impact</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>High Efficiency</td>\n",
       "      <td>Local</td>\n",
       "      <td>Recreational</td>\n",
       "      <td>Low</td>\n",
       "      <td>Moderate Engagement</td>\n",
       "      <td>Moderate Efficiency</td>\n",
       "      <td>Community Development</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Energy Consumption Carbon Emissions Waste Generation Community Engagement  \\\n",
       "0           Moderate             High             High  Moderate Engagement   \n",
       "1               High         Moderate             High  Moderate Engagement   \n",
       "2               High             High             High       Low Engagement   \n",
       "3               High             High             High  Moderate Engagement   \n",
       "4           Moderate             High              Low       Low Engagement   \n",
       "5           Moderate         Moderate             High  Moderate Engagement   \n",
       "6                Low             High         Moderate  Moderate Engagement   \n",
       "7               High             High         Moderate      High Engagement   \n",
       "8               High             High         Moderate      High Engagement   \n",
       "9               High             High             High  Moderate Engagement   \n",
       "\n",
       "  Volunteer Participation    Health Impact Water Usage  \\\n",
       "0                Moderate  Moderate Impact    Moderate   \n",
       "1                     Low       Low Impact    Moderate   \n",
       "2                    High  Moderate Impact    Moderate   \n",
       "3                Moderate  Moderate Impact    Moderate   \n",
       "4                     Low  Moderate Impact        High   \n",
       "5                    High       Low Impact    Moderate   \n",
       "6                     Low  Moderate Impact    Moderate   \n",
       "7                     Low      High Impact         Low   \n",
       "8                Moderate      High Impact         Low   \n",
       "9                    High  Moderate Impact         Low   \n",
       "\n",
       "  Material Recycling Rate Operational Cost Efficiency Event Scale  \\\n",
       "0                Moderate             High Efficiency       Local   \n",
       "1                     Low         Moderate Efficiency    National   \n",
       "2                Moderate         Moderate Efficiency    National   \n",
       "3                Moderate         Moderate Efficiency    Regional   \n",
       "4                    High             High Efficiency    Regional   \n",
       "5                     Low         Moderate Efficiency    Regional   \n",
       "6                Moderate             High Efficiency    Regional   \n",
       "7                     Low             High Efficiency    National   \n",
       "8                     Low         Moderate Efficiency       Local   \n",
       "9                     Low             High Efficiency       Local   \n",
       "\n",
       "             Event Focus Sustainability Score  Social Impact Level  \\\n",
       "0  Community Development                  Low      High Engagement   \n",
       "1  Community Development             Moderate       Low Engagement   \n",
       "2  Community Development                 High       Low Engagement   \n",
       "3  Community Development                 High       Low Engagement   \n",
       "4  Community Development                  Low  Moderate Engagement   \n",
       "5  Community Development                 High       Low Engagement   \n",
       "6          Youth-Focused                 High  Moderate Engagement   \n",
       "7  Community Development             Moderate      High Engagement   \n",
       "8  Community Development             Moderate       Low Engagement   \n",
       "9           Recreational                  Low  Moderate Engagement   \n",
       "\n",
       "   Resource Efficiency Event Type Classification  \n",
       "0  Moderate Efficiency           Health-Oriented  \n",
       "1  Moderate Efficiency              Recreational  \n",
       "2      High Efficiency              Recreational  \n",
       "3      High Efficiency              Recreational  \n",
       "4  Moderate Efficiency     Community Development  \n",
       "5  Moderate Efficiency     Community Development  \n",
       "6  Moderate Efficiency             Youth-Focused  \n",
       "7       Low Efficiency              Recreational  \n",
       "8       Low Efficiency             Youth-Focused  \n",
       "9  Moderate Efficiency     Community Development  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data\n",
    "df = pd.read_csv('sports_management_dataset.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6abda39-33b5-43b4-afa8-b618db3b9762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 102000 entries, 0 to 101999\n",
      "Data columns (total 15 columns):\n",
      " #   Column                       Non-Null Count   Dtype \n",
      "---  ------                       --------------   ----- \n",
      " 0   Energy Consumption           102000 non-null  object\n",
      " 1   Carbon Emissions             102000 non-null  object\n",
      " 2   Waste Generation             102000 non-null  object\n",
      " 3   Community Engagement         102000 non-null  object\n",
      " 4   Volunteer Participation      102000 non-null  object\n",
      " 5   Health Impact                102000 non-null  object\n",
      " 6   Water Usage                  102000 non-null  object\n",
      " 7   Material Recycling Rate      102000 non-null  object\n",
      " 8   Operational Cost Efficiency  102000 non-null  object\n",
      " 9   Event Scale                  102000 non-null  object\n",
      " 10  Event Focus                  102000 non-null  object\n",
      " 11  Sustainability Score         102000 non-null  object\n",
      " 12  Social Impact Level          102000 non-null  object\n",
      " 13  Resource Efficiency          102000 non-null  object\n",
      " 14  Event Type Classification    102000 non-null  object\n",
      "dtypes: object(15)\n",
      "memory usage: 11.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# get an overview of the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7846d46d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sustainability Score\n",
       "High        0.497029\n",
       "Moderate    0.302853\n",
       "Low         0.200118\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the number of values and percentage of total in Sustainability Score column\n",
    "df['Sustainability Score'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f1fb074-ec55-4bfc-a87b-dd83cc220e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy Consumption             3\n",
       "Carbon Emissions               3\n",
       "Waste Generation               3\n",
       "Community Engagement           3\n",
       "Volunteer Participation        3\n",
       "Health Impact                  3\n",
       "Water Usage                    3\n",
       "Material Recycling Rate        3\n",
       "Operational Cost Efficiency    3\n",
       "Event Scale                    3\n",
       "Event Focus                    4\n",
       "Sustainability Score           3\n",
       "Social Impact Level            3\n",
       "Resource Efficiency            3\n",
       "Event Type Classification      4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for number of unique values for each column to get an idea of how to encode the data\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10398e91-61e2-4fcf-9612-9e4abe15e2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Moderate\n",
       "1             High\n",
       "2             High\n",
       "3             High\n",
       "4         Moderate\n",
       "            ...   \n",
       "101995        High\n",
       "101996    Moderate\n",
       "101997    Moderate\n",
       "101998         Low\n",
       "101999        High\n",
       "Name: Energy Consumption, Length: 102000, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Energy Consumption'].str.split().str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1ecfdb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Energy Consumption</th>\n",
       "      <th>Carbon Emissions</th>\n",
       "      <th>Waste Generation</th>\n",
       "      <th>Community Engagement</th>\n",
       "      <th>Volunteer Participation</th>\n",
       "      <th>Health Impact</th>\n",
       "      <th>Water Usage</th>\n",
       "      <th>Material Recycling Rate</th>\n",
       "      <th>Operational Cost Efficiency</th>\n",
       "      <th>Event Scale</th>\n",
       "      <th>Event Focus</th>\n",
       "      <th>Sustainability Score</th>\n",
       "      <th>Social Impact Level</th>\n",
       "      <th>Resource Efficiency</th>\n",
       "      <th>Event Type Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Moderate</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>High</td>\n",
       "      <td>Local</td>\n",
       "      <td>Community Development</td>\n",
       "      <td>Low</td>\n",
       "      <td>High</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Health-Oriented</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>High</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>High</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Low</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>National</td>\n",
       "      <td>Community Development</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Low</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Recreational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>Low</td>\n",
       "      <td>High</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>National</td>\n",
       "      <td>Community Development</td>\n",
       "      <td>High</td>\n",
       "      <td>Low</td>\n",
       "      <td>High</td>\n",
       "      <td>Recreational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Community Development</td>\n",
       "      <td>High</td>\n",
       "      <td>Low</td>\n",
       "      <td>High</td>\n",
       "      <td>Recreational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Moderate</td>\n",
       "      <td>High</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Community Development</td>\n",
       "      <td>Low</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Community Development</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Energy Consumption Carbon Emissions Waste Generation Community Engagement  \\\n",
       "0           Moderate             High             High             Moderate   \n",
       "1               High         Moderate             High             Moderate   \n",
       "2               High             High             High                  Low   \n",
       "3               High             High             High             Moderate   \n",
       "4           Moderate             High              Low                  Low   \n",
       "\n",
       "  Volunteer Participation Health Impact Water Usage Material Recycling Rate  \\\n",
       "0                Moderate      Moderate    Moderate                Moderate   \n",
       "1                     Low           Low    Moderate                     Low   \n",
       "2                    High      Moderate    Moderate                Moderate   \n",
       "3                Moderate      Moderate    Moderate                Moderate   \n",
       "4                     Low      Moderate        High                    High   \n",
       "\n",
       "  Operational Cost Efficiency Event Scale            Event Focus  \\\n",
       "0                        High       Local  Community Development   \n",
       "1                    Moderate    National  Community Development   \n",
       "2                    Moderate    National  Community Development   \n",
       "3                    Moderate    Regional  Community Development   \n",
       "4                        High    Regional  Community Development   \n",
       "\n",
       "  Sustainability Score Social Impact Level Resource Efficiency  \\\n",
       "0                  Low                High            Moderate   \n",
       "1             Moderate                 Low            Moderate   \n",
       "2                 High                 Low                High   \n",
       "3                 High                 Low                High   \n",
       "4                  Low            Moderate            Moderate   \n",
       "\n",
       "  Event Type Classification  \n",
       "0           Health-Oriented  \n",
       "1              Recreational  \n",
       "2              Recreational  \n",
       "3              Recreational  \n",
       "4     Community Development  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list of columns to change\n",
    "cols = ['Community Engagement', 'Health Impact', 'Operational Cost Efficiency', 'Social Impact Level', 'Resource Efficiency']\n",
    "\n",
    "# loop through the columns and remove the second word\n",
    "for col in cols:\n",
    "    df[col] = df[col].str.split().str[0]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de746433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Energy Consumption</th>\n",
       "      <th>Carbon Emissions</th>\n",
       "      <th>Waste Generation</th>\n",
       "      <th>Community Engagement</th>\n",
       "      <th>Volunteer Participation</th>\n",
       "      <th>Health Impact</th>\n",
       "      <th>Water Usage</th>\n",
       "      <th>Material Recycling Rate</th>\n",
       "      <th>Operational Cost Efficiency</th>\n",
       "      <th>Event Scale</th>\n",
       "      <th>Event Focus</th>\n",
       "      <th>Sustainability Score</th>\n",
       "      <th>Social Impact Level</th>\n",
       "      <th>Resource Efficiency</th>\n",
       "      <th>Event Type Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Local</td>\n",
       "      <td>Community Development</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Health-Oriented</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>National</td>\n",
       "      <td>Community Development</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Recreational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>National</td>\n",
       "      <td>Community Development</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Recreational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Community Development</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Recreational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Community Development</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Community Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Community Development</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Community Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Youth-Focused</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Youth-Focused</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>National</td>\n",
       "      <td>Community Development</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Recreational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Local</td>\n",
       "      <td>Community Development</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Youth-Focused</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Local</td>\n",
       "      <td>Recreational</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Community Development</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Energy Consumption  Carbon Emissions  Waste Generation  \\\n",
       "0                 1.0               2.0               2.0   \n",
       "1                 2.0               1.0               2.0   \n",
       "2                 2.0               2.0               2.0   \n",
       "3                 2.0               2.0               2.0   \n",
       "4                 1.0               2.0               0.0   \n",
       "5                 1.0               1.0               2.0   \n",
       "6                 0.0               2.0               1.0   \n",
       "7                 2.0               2.0               1.0   \n",
       "8                 2.0               2.0               1.0   \n",
       "9                 2.0               2.0               2.0   \n",
       "\n",
       "   Community Engagement  Volunteer Participation  Health Impact  Water Usage  \\\n",
       "0                   1.0                      1.0            1.0          1.0   \n",
       "1                   1.0                      0.0            0.0          1.0   \n",
       "2                   0.0                      2.0            1.0          1.0   \n",
       "3                   1.0                      1.0            1.0          1.0   \n",
       "4                   0.0                      0.0            1.0          2.0   \n",
       "5                   1.0                      2.0            0.0          1.0   \n",
       "6                   1.0                      0.0            1.0          1.0   \n",
       "7                   2.0                      0.0            2.0          0.0   \n",
       "8                   2.0                      1.0            2.0          0.0   \n",
       "9                   1.0                      2.0            1.0          0.0   \n",
       "\n",
       "   Material Recycling Rate  Operational Cost Efficiency Event Scale  \\\n",
       "0                      1.0                          2.0       Local   \n",
       "1                      0.0                          1.0    National   \n",
       "2                      1.0                          1.0    National   \n",
       "3                      1.0                          1.0    Regional   \n",
       "4                      2.0                          2.0    Regional   \n",
       "5                      0.0                          1.0    Regional   \n",
       "6                      1.0                          2.0    Regional   \n",
       "7                      0.0                          2.0    National   \n",
       "8                      0.0                          1.0       Local   \n",
       "9                      0.0                          2.0       Local   \n",
       "\n",
       "             Event Focus  Sustainability Score  Social Impact Level  \\\n",
       "0  Community Development                   0.0                  2.0   \n",
       "1  Community Development                   1.0                  0.0   \n",
       "2  Community Development                   2.0                  0.0   \n",
       "3  Community Development                   2.0                  0.0   \n",
       "4  Community Development                   0.0                  1.0   \n",
       "5  Community Development                   2.0                  0.0   \n",
       "6          Youth-Focused                   2.0                  1.0   \n",
       "7  Community Development                   1.0                  2.0   \n",
       "8  Community Development                   1.0                  0.0   \n",
       "9           Recreational                   0.0                  1.0   \n",
       "\n",
       "   Resource Efficiency Event Type Classification  \n",
       "0                  1.0           Health-Oriented  \n",
       "1                  1.0              Recreational  \n",
       "2                  2.0              Recreational  \n",
       "3                  2.0              Recreational  \n",
       "4                  1.0     Community Development  \n",
       "5                  1.0     Community Development  \n",
       "6                  1.0             Youth-Focused  \n",
       "7                  0.0              Recreational  \n",
       "8                  0.0             Youth-Focused  \n",
       "9                  1.0     Community Development  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list of columns to encode\n",
    "encode_cols = ['Energy Consumption', 'Carbon Emissions', 'Waste Generation', 'Community Engagement', \n",
    "               'Volunteer Participation', 'Health Impact', 'Water Usage', 'Material Recycling Rate', \n",
    "               'Operational Cost Efficiency', 'Sustainability Score' ,'Social Impact Level', 'Resource Efficiency']\n",
    "\n",
    "# create a loop to encode the data\n",
    "ordinal_encoder = OrdinalEncoder(categories=[['Low', 'Moderate', 'High']])\n",
    "\n",
    "for col in encode_cols:\n",
    "    df[col] = ordinal_encoder.fit_transform(df[[col]])\n",
    "\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88ddffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEW CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35d7843",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Module 12 Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a799b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#12.1.5 Linear Regression Model\n",
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Read the electricity generation data\n",
    "file_path = \"https://static.bc-edx.com/ai/ail-v-1-0/m12/lesson_1/datasets/electricity-generation.csv\"\n",
    "df_electricity = pd.read_csv(file_path)\n",
    "\n",
    "# Display sample data\n",
    "df_electricity.head()\n",
    "\n",
    "# Create a scatter plot with the total electricity generation by year\n",
    "electricity_plot = df_electricity.plot.scatter(\n",
    "x=\"Year\",\n",
    "y=\"Total\",\n",
    "title=\"Total electricity generation by year (GHz)\"\n",
    ")\n",
    "electricity_plot\n",
    "\n",
    "## Prepare the Data to Fit the Linear Regression Model\n",
    "# Create the X set\n",
    "X = df[\"Year\"].values.reshape(-1, 1)\n",
    "\n",
    "# Display sample data\n",
    "X[:5]\n",
    "\n",
    "# Create an array for the dependent variable y with the total electricity generation data\n",
    "y = df[\"Total\"]\n",
    "\n",
    "## Build the Linear Regression Model\n",
    "# Make predictions using the X set\n",
    "predicted_y_values = model.predict(X)\n",
    "\n",
    "# Create a copy of the original data\n",
    "df_electricity_predicted = df.copy()\n",
    "\n",
    "# Add a column with the predicted electricity values\n",
    "df_electricity_predicted[\"electricity_predicted\"] = predicted_y_values\n",
    "\n",
    "# Display sample data\n",
    "df_electricity_predicted.head()\n",
    "\n",
    "# Create a line plot of the predicted total electricity generation values\n",
    "best_fit_line = df_electricity_predicted.plot.line(\n",
    "x = \"Year\",\n",
    "y = \"electricity_predicted\",\n",
    "color = \"red\")\n",
    "best_fit_line\n",
    "\n",
    "# Superpose the original data and the best fit line\n",
    "#Create a scatter plot with the electricity information\n",
    "electricity_plot = df_electricity_predicted.plot.scatter(\n",
    "x=\"Year\",\n",
    "y=\"Total\",\n",
    "title=\"Electricity Generation by Year (GHz)\")\n",
    "\n",
    "# Create a line plot of the predicted total electricity generation values\n",
    "best_fit_line = df_electricity_predicted.plot.line(\n",
    "    x = \"Year\",\n",
    "    y = \"electricity_predicted\",\n",
    "    color = \"red\",\n",
    "    ax=electricity_plot)\n",
    "electricity_plot\n",
    "\n",
    "## Make Manual Predictions\n",
    "# Display the formula to predict the electricity generation for 2023\n",
    "print(f\"Model's formula: y = {model.intercept_} + {model.coef_[0]} * 2023\")\n",
    "\n",
    "# Predict the electricity generation for 2023\n",
    "y_2023 = model.intercept_ + model.coef_[0] * 2023\n",
    "\n",
    "# Display the prediction\n",
    "print(f\"Predicted electricity generation for 2023: {y_2023:.2f}\").\n",
    "\n",
    "## Make Predictions Using the `predict` Function\n",
    "# Create an array to predict electricity generation for the years 2020, 2021, 2022, and 2023\n",
    "X_years = np.array([2020, 2021, 2022, 2023])\n",
    "\n",
    "# Format the array as a one-column array\n",
    "X_years = X_years.reshape(-1,1)\n",
    "\n",
    "# Display sample data\n",
    "X_years\n",
    "\n",
    "# Predict electricity generation for the years 2020, 2021, 2022, and 2023\n",
    "predicted_electricity = model.predict(X_years).\n",
    "\n",
    "# Create a DataFrame for the predicted electricity generation\n",
    "df_predicted_electricity = pd.DataFrame(\n",
    "    {\"Year\": X_years.reshape(1, -1)[0],\n",
    "        \"predicted_electricity\": predicted_electricity})\n",
    "\n",
    "# Display data\n",
    "df_predicted_electricity\n",
    "\n",
    "## Linear Regression Model Assessment\n",
    "# Import relevant metrics - score, r2, mse, rmse - from Scikit-learn\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Compute the metrics for the linear regression model\n",
    "score = round(model.score(X, y, sample_weight=None),5)\n",
    "r2 = round(r2_score(y, predicted_y_values),5)\n",
    "mse = round(mean_squared_error(y, predicted_y_values),4)\n",
    "rmse = round(np.sqrt(mse),4)\n",
    "\n",
    "# Print relevant metrics.\n",
    "print(f\"The score is {score}.\")\n",
    "print(f\"The r2 is {r2}.\")\n",
    "print(f\"The mean squared error is {mse}.\")\n",
    "print(f\"The root mean squared error is {rmse}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36360aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#12.1.6 Encoding\n",
    "import pandas as pd\n",
    "\n",
    "# Import the data\n",
    "# Note: NA values in this dataset are represented as \"?\"\n",
    "car_data = pd.read_csv(\"https://static.bc-edx.com/ai/ail-v-1-0/m12/lesson_1/datasets/car-data.csv\", na_values=\"?\")\n",
    "car_data\n",
    "\n",
    "# Check dtypes\n",
    "car_data.dtypes\n",
    "\n",
    "# Object features should be converted to numbers.\n",
    "# num-of-doors and num-of-cylinders are both numbers written as text.\n",
    "# Create a dictionary of the text and integers that should be converted\n",
    "str_to_int = {\"eight\": 8, \n",
    "              \"five\": 5,\n",
    "              \"four\": 4,\n",
    "              \"six\": 6,\n",
    "              \"three\": 3,\n",
    "              \"twelve\": 12,\n",
    "              \"two\": 2}\n",
    "\n",
    "# Fix the columns using the Pandas replace() method\n",
    "car_data[[\"num-of-doors\",\"num-of-cylinders\"]] = car_data[[\"num-of-doors\",\"num-of-cylinders\"]].replace(str_to_int, regex=False)\n",
    "car_data\n",
    "\n",
    "# Check dtypes\n",
    "car_data.dtypes\n",
    "\n",
    "## Pandas encoding methods\n",
    "# Encode using pd.get_dummies()\n",
    "car_data_dummies = pd.get_dummies(car_data)\n",
    "car_data_dummies.head()\n",
    "\n",
    "# Check column names\n",
    "car_data_dummies.columns\n",
    "\n",
    "# Use Pandas .astype(\"category\").cat.codes for single column category encoding\n",
    "columns_to_encode = [\"make\",\n",
    "                     \"fuel-type\",\n",
    "                     \"aspiration\",\n",
    "                     \"body-style\",\n",
    "                     \"drive-wheels\",\n",
    "                     \"engine-location\",\n",
    "                     \"engine-type\",\n",
    "                     \"fuel-system\"]\n",
    "\n",
    "# Copy car_data\n",
    "car_data_cat_codes = car_data.copy()\n",
    "\n",
    "# Loop through columns_to_encode and convert the columns to category codes\n",
    "for column in columns_to_encode:\n",
    "    car_data_cat_codes[column] = car_data_cat_codes[column].astype(\"category\").cat.codes\n",
    "\n",
    "car_data_cat_codes.head()\n",
    "\n",
    "# Check dtypes\n",
    "car_data_cat_codes.dtypes\n",
    "\n",
    "## Scikit-learn encoding methods\n",
    "# OneHotEncoder\n",
    "# Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Create an instance of OneHotEncoder()\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Fit the encoder to the data\n",
    "enc.fit(car_data[columns_to_encode])\n",
    "\n",
    "# Transform the data\n",
    "car_data_ohe = enc.transform(car_data[columns_to_encode])\n",
    "\n",
    "# Default output is sparse matrix\n",
    "car_data_ohe\n",
    "\n",
    "# Get new feature names\n",
    "enc.get_feature_names_out()\n",
    "\n",
    "# Set up the OneHotEncoder so it will transform to Pandas\n",
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "ohe.set_output(transform=\"pandas\")\n",
    "\n",
    "# Fit and transform the OneHotEncoder to the columns to encode\n",
    "car_data_ohe = ohe.fit_transform(car_data[columns_to_encode])\n",
    "car_data_ohe.head()\n",
    "\n",
    "# LabelEncoder\n",
    "# Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create an instance of the label encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Copy car_data\n",
    "car_data_label_encoded = car_data.copy()\n",
    "\n",
    "# Fit and transform the label encoder for each column\n",
    "for column in columns_to_encode:\n",
    "car_data_label_encoded[column] = le.fit_transform(car_data_label_encoded[column])\n",
    "\n",
    "car_data_label_encoded.head()\n",
    "\n",
    "# Check dtypes\n",
    "car_data_label_encoded.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ec44d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#12.1.9 Predict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Read the CSV file into a Pandas DataFrame\n",
    "Lp100km = pd.read_csv('https://static.bc-edx.com/ai/ail-v-1-0/m12/lesson_1/datasets/liters-per-100km.csv')\n",
    "Lp100km.head()\n",
    "\n",
    "## Visualize the Data to Find Any Linear Trends\n",
    "# Plot the cylinders & L/100km to find out if a linear trend exists\n",
    "Lp100km.plot.scatter(x='cylinders', y='L/100km')\n",
    "\n",
    "# Plot the displacement & L/100km to find out if a linear trend exists\n",
    "Lp100km.plot.scatter(x='displacement', y='L/100km') \n",
    "\n",
    "# Assign the variable X to the two features that appear to have the most linear relationship with L/100km\n",
    "# Note: scikit-learn requires a two-dimensional array of values\n",
    "# so we use reshape() to create this\n",
    "\n",
    "X = Lp100km[[\"weight (kg)\", \"displacement\"]].values.reshape(-1, 2)\n",
    "y = Lp100km[\"L/100km\"].values.reshape(-1, 1)\n",
    "\n",
    "print(\"Shape: \", X.shape, y.shape)\n",
    "\n",
    "# Use the Sklearn `train_test_split()` function to split the data into training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Create the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model to the training data. \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the mean_squared_error and the r-squared value\n",
    "# for the testing data\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Use our model to make predictions\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "# Score the predictions with mse and r2\n",
    "mse = mean_squared_error(y_test, predicted)\n",
    "r2 = r2_score(y_test, predicted)\n",
    "\n",
    "print(f\"mean squared error (MSE): {mse}\")\n",
    "print(f\"R-squared (R2): {r2}\")\n",
    "\n",
    "# Call the `score()` method on the model to show the R2 score\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a004f444",
   "metadata": {},
   "outputs": [],
   "source": [
    "#12.3.1 Regression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Import the data\n",
    "df = pd.read_csv(\"https://static.bc-edx.com/ai/ail-v-1-0/m12/lesson_3/datasets/rent-data-label-encoded.csv\")\n",
    "df.head()\n",
    "\n",
    "# Drop rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "## Split into training and testing sets\n",
    "# Make an X variable with all columns except price\n",
    "X_full = df.drop(columns = ['price'])\n",
    "X_full.columns\n",
    "\n",
    "select_features = [\"square_feet\", \"Gated\", \"bathrooms\", \"bedrooms\", \"has_photo\", \"Pool\", \"AC\"]\n",
    "\n",
    "# Create another variable X_sel with only the columns\n",
    "# in the \"select_features\" list\n",
    "\n",
    "X_sel = df[select_features]\n",
    "X_sel.head()\n",
    "\n",
    "# Set the target variable y\n",
    "y = df[\"price\"].values.reshape(-1, 1)\n",
    "\n",
    "# Now split the data into training and testing sets\n",
    "X_full_train, X_full_test, X_sel_train, X_sel_test, y_train, y_test = train_test_split(X_full, X_sel, y, random_state=42)\n",
    "\n",
    "## Train the models\n",
    "# Create the models\n",
    "lr1 = LinearRegression()\n",
    "lr2 = LinearRegression()\n",
    "\n",
    "# Fit the first model to the full training data. \n",
    "lr1.fit(X_full_train, y_train)\n",
    "\n",
    "# Fit the second model to the select training data.\n",
    "lr2.fit(X_sel_train, y_train)\n",
    "\n",
    "## Evaluate the model\n",
    "# Calculate the mean_squared_error and the r-squared value\n",
    "# for the testing data\n",
    "\n",
    "# Use our models to make predictions\n",
    "predicted1 = lr1.predict(X_full_test)\n",
    "predicted2 = lr2.predict(X_sel_test)\n",
    "\n",
    "# Score the predictions with mse and r2\n",
    "mse1 = mean_squared_error(y_test, predicted1)\n",
    "r21 = r2_score(y_test, predicted1)\n",
    "mse2 = mean_squared_error(y_test, predicted2)\n",
    "r22 = r2_score(y_test, predicted2)\n",
    "\n",
    "print(f\"All Features:\")\n",
    "print(f\"mean squared error (MSE): {mse1}\")\n",
    "print(f\"R-squared (R2): {r21}\")\n",
    "print(\"---------------------\")\n",
    "print(f\"Select Features:\")\n",
    "print(f\"mean squared error (MSE): {mse2}\")\n",
    "print(f\"R-squared (R2): {r22}\")\n",
    "\n",
    "# Provided code to create the adjusted r-squared function\n",
    "def r2_adj(x, y, model):\n",
    "    r2 = model.score(x,y)\n",
    "    n_cols = x.shape[1]\n",
    "    return 1 - (1 - r2) * (len(y) - 1) / (len(y) - n_cols - 1)\n",
    "\n",
    "# Calculate the adjusted r-squared value of the model\n",
    "adj_score1 = r2_adj(X_full_test, y_test, lr1)\n",
    "adj_score2 = r2_adj(X_sel_test, y_test, lr2)\n",
    "print(f\"All Features Adjusted R2: {adj_score1}\")\n",
    "print(f\"Select Features Adjusted R2: {adj_score2}\")\n",
    "\n",
    "# Examine linear regression on the better training data using cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cv_scores = cross_val_score(LinearRegression(), X_full_train, y_train, scoring = \"r2\")\n",
    "print(f\"All scores: {cv_scores}\")\n",
    "print(f\"Mean score: {cv_scores.mean()}\")\n",
    "print(f\"Standard Deviation: {cv_scores.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2d03fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#12.2.7 Ridge and Lasso regression model\n",
    "# Ridge - A ridge regression model is a type of linear regression model that addresses the issue of multicollinearity \n",
    "#   (highly correlated independent variables) by adding a penalty term to the regression equation, effectively shrinking \n",
    "#   the coefficients towards zero and stabilizing the model, preventing overfitting; it's considered a form of regularization, \n",
    "#   specifically known as L2 regularization.\n",
    "#   MSE tells you how well the model is performing on average, while simultaneously performing feature selection by shrinking \n",
    "#   someells you how well the model is performing by measuring the average squared difference between its predicted values and \n",
    "#   the actual values\n",
    "#   A good mse score is a low value, close to zero.\n",
    "# Lasso - Lasso regression, or Least Absolute Shrinkage and Selection Operator, is a regularization technique that improves the \n",
    "#   accuracy of statistical models by preventing overfitting.\n",
    "#   MSE tells you how well the model is performing on average, while simultaneously performing feature selection by shrinking some \n",
    "#   coefficients to zero, making it useful for understanding which variables are most important in the prediction process. \n",
    "#   A good mse score is a low value, close to zero.\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://static.bc-edx.com/ai/ail-v-1-0/m12/lesson_2/datasets/real-estate-evaluation.csv')\n",
    "df.head()\n",
    "\n",
    "# Separate the data into features and target \n",
    "X = df.drop('Y house price of unit area', axis=1)\n",
    "y = df['Y house price of unit area']\n",
    "\n",
    "# Check the features shape \n",
    "X.shape\n",
    "\n",
    "### Perform ridge regression\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# Scale the training data\n",
    "scaler = StandardScaler()\n",
    "X_train_transformed = scaler.fit_transform(X_train)\n",
    "\n",
    "# Create and train the model\n",
    "model = Ridge(alpha=1)\n",
    "model.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Scale the testing data and create predictions\n",
    "X_test_transformed = scaler.transform(X_test)\n",
    "y_predicted = model.predict(X_test_transformed)\n",
    "\n",
    "# Assess the MSE\n",
    "mean_squared_error(y_test, y_predicted)\n",
    "\n",
    "# Use RidgeCV to optimize for alpha\n",
    "from sklearn.linear_model import RidgeCV\n",
    "model_cv = RidgeCV(alphas=[0.001, 0.01, 0.1, 1, 10])\n",
    "model_cv = model_cv.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Identify the optimzied alpha value\n",
    "model_cv.alpha_\n",
    "\n",
    "# Compare performance with a linear regression model\n",
    "# Create and train a linear regression model, create predictions with the model, and evaluate its MSE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_transformed, y_train)\n",
    "y_predicted_lr = lr_model.predict(X_test_transformed)\n",
    "mean_squared_error(y_test, y_predicted_lr)\n",
    "\n",
    "### Lasso regression\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Create and train a lasso regression model\n",
    "lasso_model = Lasso(alpha=1)\n",
    "lasso_model.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Get the model coeffcients\n",
    "lasso_model.coef_\n",
    "\n",
    "# Create predictions with the model\n",
    "y_predicted_lasso = lasso_model.predict(X_test_transformed)\n",
    "\n",
    "### Assess the lasso regression MSE and compare to ridge regression\n",
    "# Evaluate the MSE\n",
    "mean_squared_error(y_test, y_predicted_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630d445b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Do we want to create a pipeline? If so, see 12.3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc87216",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Module 13 Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a6458d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#13.1.2 Logistics Regression Model\n",
    "## Prepare the Data\n",
    "# Import the required modules\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Read in the app-data.csv file into a Pandas DataFrame.\n",
    "file_path = \"https://static.bc-edx.com/ai/ail-v-1-0/m13/lesson_1/datasets/app-data.csv\"\n",
    "app_data = pd.read_csv(file_path)\n",
    "\n",
    "# Review the DataFrame\n",
    "app_data.head()\n",
    "\n",
    "# The column 'Result' is the thing you want to predict. \n",
    "# Class 0 indicates a benign app and class 1 indicates a malware app\n",
    "# Using value_counts, how many malware apps are in this dataset?\n",
    "app_data[\"Result\"].value_counts()\n",
    "\n",
    "## Split the data into training and testing sets\n",
    "# Import Module\n",
    "from sklearn.model_selection import train_test_split\n",
    "# The target column `y` should be the binary `Result` column.\n",
    "y = app_data[\"Result\"]\n",
    "\n",
    "# The `X` should be all of the features. \n",
    "X = app_data.copy()\n",
    "X = X.drop(columns=\"Result\")\n",
    "\n",
    "# Split the dataset using the train_test_split function\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "## Model and Fit the Data to a Logistic Regression\n",
    "# Import `LogisticRegression` from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Declare a logistic regression model.\n",
    "# Apply a random_state of 7 and max_iter of 120 to the model\n",
    "logistic_regression_model = LogisticRegression(random_state=7, max_iter=120)\n",
    "\n",
    "# Fit and save the logistic regression model using the training data\n",
    "lr_model = logistic_regression_model.fit(X_train, y_train)\n",
    "\n",
    "# Validate the model\n",
    "print(f\"Training Data Score: {lr_model.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {lr_model.score(X_test, y_test)}\")\n",
    "\n",
    "## Predict the Testing Labels\n",
    "# Generate predictions from the model we just fit\n",
    "predictions = logistic_regression_model.predict(X_train)\n",
    "\n",
    "# Convert those predictions (and actual values) to a DataFrame\n",
    "results_df = pd.DataFrame({\"Prediction\": predictions, \"Actual\": y_train})\n",
    "results_df\n",
    "\n",
    "# Make and save testing predictions with the saved logistic regression model using the test data\n",
    "testing_predections = lr_model.predict(X_test)\n",
    "\n",
    "# Review the predictions\n",
    "testing_predections\n",
    "\n",
    "## Calculate the Performance Metrics\n",
    "# Import the accuracy_score function\n",
    "from sklearn.metrics import accuracy_score\n",
    "    \n",
    "# Display the accuracy score for the test dataset.\n",
    "accuracy_score(y_test, testing_predections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f0b322",
   "metadata": {},
   "outputs": [],
   "source": [
    "#13.1.6 SVM Model\n",
    "# Import required dependencies\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "# Import data\n",
    "file_path = \"https://static.bc-edx.com/ai/ail-v-1-0/m13/lesson_1/datasets/app-data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()\n",
    "\n",
    "## Split the data into training and testing sets\n",
    "# Get the target variable (the \"Result\" column)\n",
    "y = df[\"Result\"]\n",
    "\n",
    "# Get the features (everything except the \"Result\" column)\n",
    "X = df.copy()\n",
    "X = X.drop(columns=\"Result\")\n",
    "X.head()\n",
    "\n",
    "# Split data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "## Model and Fit to a Support Vector Machine\n",
    "# Create the support vector machine classifier model with a 'linear' kernel\n",
    "model = SVC(kernel='linear')\n",
    "    \n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Validate the model by checking the model accuracy with model.score\n",
    "print('Train Accuracy: %.3f' % model.score(X_train, y_train))\n",
    "print('Test Accuracy: %.3f' % model.score(X_test, y_test))\n",
    "\n",
    "## Predict the Testing Labels\n",
    "# Make and save testing predictions with the saved SVM model using the testing data\n",
    "testing_predictions = model.predict(X_test)\n",
    "\n",
    "# Review the predictions\n",
    "testing_predictions\n",
    "\n",
    "## Evaluate the Model\n",
    "# Display the accuracy score for the testing dataset\n",
    "accuracy_score(y_test, testing_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd46a381",
   "metadata": {},
   "outputs": [],
   "source": [
    "#13.2.2 KNN Model\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define features set\n",
    "X = app_data.copy()\n",
    "X.drop(\"Result\", axis=1, inplace=True)\n",
    "X.head()\n",
    "\n",
    "# Define target vector\n",
    "y = app_data[\"Result\"]\n",
    "y.head()\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=3)\n",
    "\n",
    "# Create a StandardScaler() model and fit it to the training data\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "# Transform the training and testing data by using the X_scaler model\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# K-nearest neighbors\n",
    "# Loop through different k values to find which has the highest accuracy.\n",
    "# Note: We use only odd numbers because we don't want any ties.\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 20, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    train_score = knn.score(X_train_scaled, y_train)\n",
    "    test_score = knn.score(X_test_scaled, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "    \n",
    "# Plot the results\n",
    "plt.plot(range(1, 20, 2), train_scores, marker='o', label=\"training scores\")\n",
    "plt.plot(range(1, 20, 2), test_scores, marker=\"x\", label=\"testing scores\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"accuracy score\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Choose the best k, and refit the KNN classifier by using that k value.\n",
    "# Note that k: 9 provides the best accuracy where the classifier starts to stablize\n",
    "knn = KNeighborsClassifier(n_neighbors=9)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the score for the test data.\n",
    "print('k=9 Test Acc: %.3f' % knn.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cc212f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#13.2.4 Decision Tree Model\n",
    "# Initial imports\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Needed for decision tree visualization\n",
    "import pydotplus\n",
    "from IPython.display import Image\n",
    "\n",
    "# *Skipped loading data\n",
    "\n",
    "# Define features set\n",
    "X = app_data.copy()\n",
    "X.drop(\"Result\", axis=1, inplace=True)\n",
    "X.head()\n",
    "\n",
    "# Define target vector\n",
    "y = app_data[\"Result\"].values.reshape(-1, 1)\n",
    "y[:5]\n",
    "\n",
    "# Splitting into Train and Test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)\n",
    "\n",
    "# Create the StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler with the training data\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the training data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "## Fitting the Decision Tree Model\n",
    "# Create the decision tree classifier instance\n",
    "model = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Fit the model\n",
    "model = model.fit(X_train_scaled, y_train)\n",
    "\n",
    "## Making Predictions Using the Tree Model\n",
    "# Making predictions using the testing data\n",
    "predictions = model.predict(X_test_scaled)\n",
    "\n",
    "## Model Evaluation\n",
    "# Calculate the accuracy score\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "\n",
    "## Visualizing the Decision Tree\n",
    "# Create DOT data\n",
    "dot_data = tree.export_graphviz(\n",
    "    model, out_file=None, feature_names=X.columns, class_names=[\"0\", \"1\"], filled=True, max_depth=5\n",
    ")\n",
    "\n",
    "# Draw graph\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "\n",
    "# Show graph\n",
    "Image(graph.create_png())\n",
    "\n",
    "# When saving the image, graph.write_<file_type>() must take a string object\n",
    "\n",
    "# Save the tree as PDF\n",
    "file_path = \"malware_tree.pdf\"\n",
    "graph.write_pdf(file_path)\n",
    "\n",
    "# Save the tree as PNG\n",
    "file_path = \"malware_tree.png\"\n",
    "graph.write_png(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cafeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#13.2.5 & 13.2.6 Random Forest\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# *Skipped loading data\n",
    "\n",
    "## Loading and Preprocessing Malware Apps Data\n",
    "# Define features set\n",
    "X = df_apps.copy()\n",
    "X.drop(\"Result\", axis=1, inplace=True)\n",
    "X.head()\n",
    "\n",
    "# Define target set\n",
    "y = df_apps[\"Result\"].ravel()\n",
    "y[:5]\n",
    "\n",
    "## Fitting the Random Forest Model\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train the Random Forest model\n",
    "clf = RandomForestClassifier(random_state=1, n_estimators=500).fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f'Training Score: {clf.score(X_train_scaled, y_train)}')\n",
    "print(f'Testing Score: {clf.score(X_test_scaled, y_test)}')\n",
    "\n",
    "# Get the feature importance array\n",
    "feature_importances = clf.feature_importances_\n",
    "\n",
    "# List the top 10 most important features\n",
    "importances_sorted = sorted(zip(feature_importances, X.columns), reverse=True)\n",
    "importances_sorted[:10]\n",
    "\n",
    "# Plot the feature importances\n",
    "features = sorted(zip(X.columns, feature_importances), key = lambda x: x[1])\n",
    "cols = [f[0] for f in features]\n",
    "width = [f[1] for f in features]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "fig.set_size_inches(8,6)\n",
    "plt.margins(y=0.001)\n",
    "\n",
    "ax.barh(y=cols, width=width)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "## Making Predictions Using the Random Forest Model\n",
    "# Make predictions using the testing data\n",
    "predictions = rf_model.predict(X_test)\n",
    "\n",
    "## Model Evaluation\n",
    "# Get the feature importance array\n",
    "importances = rf_model.feature_importances_\n",
    "# List the top 10 most important features\n",
    "importances_sorted = sorted(zip(rf_model.feature_importances_, X.columns), reverse=True)\n",
    "importances_sorted[:10]\n",
    "\n",
    "## Analysis Questions\n",
    "\n",
    "Finally, analyze the model's evaluation results and answer the following questions.\n",
    "\n",
    "* **Question:** Would you trust this model to detect malware? \n",
    "\n",
    "    * **Sample Answer:** Yes. The model's accuracy is good at predicting malware because of the high accuracy. \n",
    "\n",
    "* **Question:** Out of the following models, which one had the highest accuracy score: logistic regression, SVM, \n",
    "KNN, decision tree, or random forest?\n",
    "\n",
    "    * **Sample Answer:** Random forest performed marginally better (about 0.007) than the other models, which all \n",
    "performed in a similar range. Other performance metrics should be calculated to determine the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a319697",
   "metadata": {},
   "outputs": [],
   "source": [
    "#13.2.7 Extra Trees Model, Gradient Boosting Model and Adaptive Boosting Model\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Read the forest cover dataset\n",
    "df = pd.read_csv('https://static.bc-edx.com/ai/ail-v-1-0/m13/lesson_2/datasets/covtype.csv')\n",
    "\n",
    "# Split the features and target\n",
    "X = df.drop('cover', axis=1)\n",
    "y = df['cover']\n",
    "target_names = [\"Spruce/Fir\", \"Lodgepole Pine\"]\n",
    "\n",
    "# Prepare the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train the ExtraTreesClassifier model\n",
    "clf = ExtraTreesClassifier(random_state=1).fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f'Training Score: {clf.score(X_train_scaled, y_train)}')\n",
    "print(f'Testing Score: {clf.score(X_test_scaled, y_test)}')\n",
    "\n",
    "# Train the Gradient Boosting classifier\n",
    "clf = GradientBoostingClassifier(random_state=1).fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f'Training Score: {clf.score(X_train_scaled, y_train)}')\n",
    "print(f'Testing Score: {clf.score(X_test_scaled, y_test)}')\n",
    "\n",
    "# Train the AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(random_state=1).fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f'Training Score: {clf.score(X_train_scaled, y_train)}')\n",
    "print(f'Testing Score: {clf.score(X_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c777557b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#13.3.1 Runs through multiple models\n",
    "# Import required dependencies\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Import data\n",
    "file_path = \"https://static.bc-edx.com/ai/ail-v-1-0/m13/lesson_3/datasets/tic-tac-toe.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()\n",
    "\n",
    "## Preprocess the data\n",
    "# Check the data types\n",
    "df.dtypes\n",
    "\n",
    "# Get the target variable (the \"Class\" column)\n",
    "# Since the target column is an object, we need to convert the data to numerical classes\n",
    "# Use the LabelEncoder\n",
    "\n",
    "# Create an instance of the label encoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df[\"Class\"])\n",
    "y\n",
    "\n",
    "# Get the features (everything except the \"Class\" column)\n",
    "X = df.copy()\n",
    "X = X.drop(columns=\"Class\")\n",
    "X.head()\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Remember that all of the columns in the DataFrame are objects\n",
    "# Use a OneHotEncoder to convert the training and testing data to numerical values\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False, dtype='int')\n",
    "X_train_encoded = pd.DataFrame(data=ohe.fit_transform(X_train), columns=ohe.get_feature_names_out())\n",
    "X_test_encoded = pd.DataFrame(data=ohe.transform(X_test), columns=ohe.get_feature_names_out())\n",
    "X_train_encoded\n",
    "\n",
    "## Model and Fit to a Logistic Regression Classifier\n",
    "# Create the logistic regression classifier model with a random_state of 1\n",
    "lr_model = LogisticRegression(random_state=1)\n",
    "\n",
    "# Fit the model to the training data\n",
    "lr_model.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Validate the model by checking the model accuracy with model.score\n",
    "print('Train Accuracy: %.3f' % lr_model.score(X_train_encoded, y_train))\n",
    "print('Test Accuracy: %.3f' % lr_model.score(X_test_encoded, y_test))\n",
    "\n",
    "## Model and Fit to a Support Vector Machine\n",
    "# Create the support vector machine classifier model with a 'linear' kernel\n",
    "svm_model = SVC(kernel='linear')\n",
    "\n",
    "# Fit the model to the training data\n",
    "svm_model.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Validate the model by checking the model accuracy with model.score\n",
    "print('Train Accuracy: %.3f' % svm_model.score(X_train_encoded, y_train))\n",
    "print('Test Accuracy: %.3f' % svm_model.score(X_test_encoded, y_test))\n",
    "\n",
    "## Model and Fit to a KNN model\n",
    "# Create the KNN model with 5 neighbors\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Fit the model to the training data\n",
    "knn_model.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Validate the model by checking the model accuracy with model.score\n",
    "print('Train Accuracy: %.3f' % knn_model.score(X_train_encoded, y_train))\n",
    "print('Test Accuracy: %.3f' % knn_model.score(X_test_encoded, y_test))\n",
    "\n",
    "## Model and Fit to a Decision Tree Classifier\n",
    "# Create the decision tree classifier model\n",
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "# Fit the model to the training data\n",
    "dt_model.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Validate the model by checking the model accuracy with model.score\n",
    "print('Train Accuracy: %.3f' % dt_model.score(X_train_encoded, y_train))\n",
    "print('Test Accuracy: %.3f' % dt_model.score(X_test_encoded, y_test))\n",
    "\n",
    "## Model and Fit to a Random Forest Classifier\n",
    "# Create the random forest classifier model\n",
    "# with n_estimators=128 and random_state=1\n",
    "rf_model = RandomForestClassifier(n_estimators=128, random_state=1)\n",
    "\n",
    "# Fit the model to the training data\n",
    "rf_model.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Validate the model by checking the model accuracy with model.score\n",
    "print('Train Accuracy: %.3f' % rf_model.score(X_train_encoded, y_train))\n",
    "print('Test Accuracy: %.3f' % rf_model.score(X_test_encoded, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202d1f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#13.3.2 Irish Decision Tree\n",
    "from sklearn import tree\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "import pydotplus\n",
    "from IPython.display import Image\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Create and score a decision tree classifier\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(iris.data, iris.target)\n",
    "clf.score(iris.data, iris.target)\n",
    "\n",
    "# Create a decision tree graph\n",
    "dot_data = tree.export_graphviz(\n",
    "    clf, out_file=None, \n",
    "    feature_names=iris.feature_names,  \n",
    "    class_names=iris.target_names,  \n",
    "    filled=True, rounded=True,  \n",
    "    special_characters=True)  \n",
    "\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "graph.write_png('iris.png')\n",
    "\n",
    "# Show graph\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d071aad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#13.3.4 Regressors\n",
    "%matplotlib widget\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import make_regression, make_swiss_roll\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def test_model(model, data):\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test = data\n",
    "    reg = model.fit(X_train_scaled, y_train)\n",
    "    print(f'Model: {type(reg).__name__}')\n",
    "    print(f'Train score: {reg.score(X_train_scaled, y_train)}')\n",
    "    print(f'Test Score: {reg.score(X_test_scaled, y_test)}\\n')\n",
    "\n",
    "# Create data\n",
    "X, y = make_regression(random_state=1)\n",
    "X = pd.DataFrame(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "data = [X_train_scaled, X_test_scaled, y_train, y_test]\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "test_model(LinearRegression(), data)\n",
    "test_model(KNeighborsRegressor(), data)\n",
    "test_model(RandomForestRegressor(), data)\n",
    "test_model(ExtraTreesRegressor(), data)\n",
    "test_model(AdaBoostRegressor(), data)\n",
    "test_model(SVR(C=1.0, epsilon=0.2), data)\n",
    "\n",
    "# Create data\n",
    "X, y = make_swiss_roll(random_state=1, n_samples=500, noise=1)\n",
    "X = pd.DataFrame(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "data = [X_train_scaled, X_test_scaled, y_train, y_test]\n",
    "\n",
    "X_train_scaled\n",
    "\n",
    "# Plot the result (requires matplotlib>=3.9)\n",
    "ax = plt.figure().add_subplot(projection='3d')\n",
    "ax.view_init(7, -80)\n",
    "ax.scatter(X[0], X[1], X[2],\n",
    "           color=plt.cm.jet(y/y.max()),\n",
    "           s=20, edgecolor='k')\n",
    "plt.savefig(\"swiss_roll.png\")\n",
    "plt.show()\n",
    "\n",
    "test_model(LinearRegression(), data)\n",
    "test_model(KNeighborsRegressor(), data)\n",
    "test_model(RandomForestRegressor(), data)\n",
    "test_model(ExtraTreesRegressor(), data)\n",
    "test_model(AdaBoostRegressor(), data)\n",
    "test_model(SVR(C=1.0, epsilon=0.2), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a295017",
   "metadata": {},
   "outputs": [],
   "source": [
    "#14.1.4 Metrics\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, balanced_accuracy_score, roc_auc_score\n",
    "\n",
    "# Import the data\n",
    "df = pd.read_csv(\"https://static.bc-edx.com/ai/ail-v-1-0/m14/lesson_1/datasets/crowdfunding-data-imbalanced.csv\")\n",
    "df.head()\n",
    "\n",
    "# Show the total number of positive and negative outcomes\n",
    "df['outcome'].value_counts()\n",
    "\n",
    "# Create an X and y variable\n",
    "X = df.drop(columns=['outcome'])\n",
    "y = df['outcome']\n",
    "\n",
    "# Create a Logistic Regression Model\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "classifier.fit(X, y)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "classifier.score(X, y)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = classifier.predict(X)\n",
    "\n",
    "# Create a confusion matrix\n",
    "print(confusion_matrix(y, predictions, labels = [1,0]))\n",
    "\n",
    "# Create a classification report\n",
    "print(classification_report(y, predictions, labels = [1, 0]))\n",
    "\n",
    "# Calculate the balanced accuracy score\n",
    "print(balanced_accuracy_score(y, predictions))\n",
    "\n",
    "# Predict values with probabilities\n",
    "pred_probas = classifier.predict_proba(X)\n",
    "\n",
    "# Print the probabilities\n",
    "pred_probas\n",
    "\n",
    "# Each prediction includes a prediction for both the 0 class and the 1 class\n",
    "# We only need the predictions for the 1 class; use a list comprehension to \n",
    "# gather the second value from each list\n",
    "\n",
    "pred_probas_firsts = [prob[1] for prob in pred_probas]\n",
    "\n",
    "# Print the first 5 probabilities\n",
    "pred_probas_firsts[0:5]\n",
    "\n",
    "# Calculate the roc_auc_score\n",
    "print(roc_auc_score(y, pred_probas_firsts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531536dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#14.1.7 Overfitting (another example is 14.3.1 to show the max depth if overfitted)\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Import the data\n",
    "df = pd.read_csv(\"https://static.bc-edx.com/ai/ail-v-1-0/m13/lesson_2/datasets/crowdfunding-data.csv\")\n",
    "df.info()\n",
    "\n",
    "# Create an X and y variable\n",
    "X = df.drop(columns=['outcome'])\n",
    "y = df['outcome']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# Create a Random Forest model\n",
    "classifier = RandomForestClassifier()\n",
    "\n",
    "# Fit (train) or model using the training data\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Check the model's balanced accuracy on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "print(balanced_accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Check the model's balanced accuracy on the training set\n",
    "y_train_pred = model.predict(X_train)\n",
    "print(balanced_accuracy_score(y_train, y_train_pred))\n",
    "\n",
    "# Calculate the accuracy of the model on the testing data\n",
    "classifier.score(X_test, y_test)\n",
    "\n",
    "# Calculate the accuracy of the model on the training data\n",
    "classifier.score(X_train, y_train)\n",
    "\n",
    "# Create a loop to vary the max_depth parameter\n",
    "# Make sure to record the train and test scores \n",
    "# for each pass.\n",
    "\n",
    "# Depths should span from 1 up to 15 in steps of 1\n",
    "depths = range(1, 15)\n",
    "\n",
    "# The scores dataframe will hold depths and scores\n",
    "# to make plotting easy\n",
    "scores = {'train': [], 'test': [], 'depth': []}\n",
    "\n",
    "# Loop through each depth\n",
    "for depth in depths:\n",
    "    clf = RandomForestClassifier(max_depth=depth)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    train_score = clf.score(X_train, y_train)\n",
    "    test_score = clf.score(X_test, y_test)\n",
    "\n",
    "    scores['depth'].append(depth)\n",
    "    scores['train'].append(train_score)\n",
    "    scores['test'].append(test_score)\n",
    "\n",
    "# Create a dataframe from the scores dictionary and\n",
    "# set the index to depth\n",
    "scores_df = pd.DataFrame(scores).set_index('depth')\n",
    "\n",
    "# Plot the scores dataframe with the plot method\n",
    "scores_df.plot()\n",
    "\n",
    "# Fit the model with the best max_depth\n",
    "clf = RandomForestClassifier(max_depth=6, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "train_pred = clf.predict(X_train)\n",
    "test_pred = clf.predict(X_test)\n",
    "\n",
    "# Print the train and test balanced accuracy scores\n",
    "print(balanced_accuracy_score(y_train, train_pred))\n",
    "print(balanced_accuracy_score(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6d0ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#14.2.3 Data Leakage and Correlation\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import the data\n",
    "df = pd.read_csv(\"https://static.bc-edx.com/ai/ail-v-1-0/m14/lesson_2/datasets/crowdfunding-data-leakage.csv\")\n",
    "\n",
    "# Create an X and y variable\n",
    "X = df.drop(columns=['outcome'])\n",
    "y = df['outcome']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 13)\n",
    "\n",
    "# Create a Random Forest Model\n",
    "classifier = RandomForestClassifier(random_state=13)\n",
    "\n",
    "# Fit (train) or model using the training data\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the accuracy of the model with training data\n",
    "classifier.score(X_train, y_train)\n",
    "\n",
    "# Calculate the accuracy of the model with testing data\n",
    "classifier.score(X_test, y_test)\n",
    "\n",
    "# Identify any columns that could be leaking data\n",
    "df.head()\n",
    "\n",
    "# Check correlation of columns to the outcome column\n",
    "df.corr()['outcome'].sort_values()\n",
    "\n",
    "# Plot rewards_given and outcome in a scatter plot\n",
    "df.plot(kind='scatter', x='rewards_given', y='outcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bd4469",
   "metadata": {},
   "outputs": [],
   "source": [
    "#14.2.5 Encoding\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import the data\n",
    "df = pd.read_csv('https://static.bc-edx.com/ai/ail-v-1-0/m14/lesson_2/datasets/text-data.csv')\n",
    "df.head()\n",
    "\n",
    "# Create X and y and split into training and testing sets\n",
    "X = df.drop(columns='arrived')\n",
    "y = df['arrived']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=13)\n",
    "\n",
    "# Decide how to encode the backpack_color column\n",
    "X_train['backpack_color'].value_counts()\n",
    "\n",
    "# Create an encoder for the backpack_color column\n",
    "backpack_color_ohe = OneHotEncoder(drop='first', handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "# Train the encoder\n",
    "backpack_color_ohe.fit(X_train['backpack_color'].values.reshape(-1,1))\n",
    "\n",
    "# Decide how to encode the grade column\n",
    "df['grade'].value_counts()\n",
    "\n",
    "# Create an encoder for the backpack_color column\n",
    "grade_ord_enc = OrdinalEncoder(categories = [['F', 'D', 'C', 'B', 'A']], encoded_missing_value=-1, handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "# Train the encoder\n",
    "grade_ord_enc.fit(X_train['grade'].values.reshape(-1,1))\n",
    "\n",
    "# Decide how to encode the favorite_creature column\n",
    "df['favorite_creature'].value_counts()\n",
    "\n",
    "# Create an encoder for the backpack_color column\n",
    "creature_ohe = OneHotEncoder(handle_unknown='infrequent_if_exist', sparse_output=False, min_frequency=0.2)\n",
    "\n",
    "# Train the encoder\n",
    "creature_ohe.fit(X_train['favorite_creature'].values.reshape(-1,1))\n",
    "\n",
    "# Create a function using the pretrained encoders to use on\n",
    "# any new data (including the testing data)\n",
    "\n",
    "def X_preprocess(X_data):\n",
    "    # Transform each column into numpy arrays\n",
    "    backpack_color_encoded = backpack_color_ohe.transform(X_data['backpack_color'].values.reshape(-1,1))\n",
    "    grade_encoded = grade_ord_enc.transform(X_data['grade'].values.reshape(-1,1))\n",
    "    favorite_creature_encoded = creature_ohe.transform(X_data['favorite_creature'].values.reshape(-1,1))\n",
    "\n",
    "    # Reorganize the numpy arrays into a DataFrame\n",
    "    backpack_color_df = pd.DataFrame(backpack_color_encoded, columns = backpack_color_ohe.get_feature_names_out())\n",
    "    creature_df = pd.DataFrame(favorite_creature_encoded, columns= creature_ohe.get_feature_names_out())\n",
    "    out_df = pd.concat([backpack_color_df, creature_df], axis = 1)\n",
    "    out_df['grade'] = grade_encoded\n",
    "\n",
    "    # Return the DataFrame\n",
    "    return out_df\n",
    "\n",
    "# Preprocess the training data\n",
    "X_preprocess(X_train)\n",
    "\n",
    "# Preprocess the testing data\n",
    "X_preprocess(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd9b5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#14.3.2 Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb498b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#14.3.4 Resampling\n",
    "## Prepare the Data\n",
    "\n",
    "# Import modules\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Read the CSV file into a Pandas DataFrame\n",
    "bank_data_df = pd.read_csv('../Resources/bank.csv')\n",
    "\n",
    "# Review the DataFrame\n",
    "bank_data_df.head()\n",
    "\n",
    "# Split the features and target data\n",
    "y = bank_data_df['y']\n",
    "X = bank_data_df.drop(columns='y')\n",
    "\n",
    "# Encode the features dataset's categorical variables using get_dummies\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Review the features DataFrame\n",
    "X.head()\n",
    "\n",
    "# Split data into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# Review the distinct values from y\n",
    "y_train.value_counts()\n",
    "\n",
    "# Instantiate a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the training data to the standard scaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Transform the training data using the scaler\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "\n",
    "# Transform the testing data using the scaler\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "## RandomForestClassifier\n",
    "# Import the RandomForestClassifier from sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Instantiate a RandomForestClassifier instance\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Fit the traning data to the model\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict labels for original scaled testing features\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "## Random Undersampler\n",
    "# Import RandomUnderSampler from imblearn\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Instantiate a RandomUnderSampler instance\n",
    "rus = RandomUnderSampler(random_state=1)\n",
    "\n",
    "# Fit the training data to the random undersampler model\n",
    "X_undersampled, y_undersampled = rus.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Count distinct values for the resampled target data\n",
    "y_undersampled.value_counts()\n",
    "\n",
    "# Instantiate a new RandomForestClassier model\n",
    "model_undersampled = RandomForestClassifier()\n",
    "\n",
    "# Fit the undersampled data the new model\n",
    "model_undersampled.fit(X_undersampled, y_undersampled)\n",
    "\n",
    "# Predict labels for oversampled testing features\n",
    "y_pred_undersampled = model_undersampled.predict(X_test_scaled)\n",
    "\n",
    "# Print classification reports\n",
    "print(f\"Classification Report - Original Data\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"---------\")\n",
    "print(f\"Classification Report - Undersampled Data\")\n",
    "print(classification_report(y_test, y_pred_undersampled))\n",
    "\n",
    "## Random Oversampler\n",
    "# Import RandomOverSampler from imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Instantiate a RandomOversampler instance\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "\n",
    "# Fit the training data to the `RandomOverSampler` model\n",
    "X_oversampled, y_oversampled = ros.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Count distinct values\n",
    "y_oversampled.value_counts()\n",
    "\n",
    "# Instantiate a new RandomForestClassier model\n",
    "model_oversampled = RandomForestClassifier()\n",
    "\n",
    "# Fit the oversampled data the new model\n",
    "model_oversampled.fit(X_oversampled, y_oversampled)\n",
    "\n",
    "# Predict labels for oversampled testing features\n",
    "y_pred_oversampled = model_oversampled.predict(X_test_scaled)\n",
    "\n",
    "# Print classification reports\n",
    "print(f\"Classification Report - Original Data\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"---------\")\n",
    "print(f\"Classification Report - Undersampled Data\")\n",
    "print(classification_report(y_test, y_pred_undersampled))\n",
    "print(\"---------\")\n",
    "print(f\"Classification Report - Oversampled Data\")\n",
    "print(classification_report(y_test, y_pred_oversampled))\n",
    "\n",
    "## Cluster Centroids\n",
    "# Import ClusterCentroids from imblearn\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "\n",
    "# Instantiate a ClusterCentroids instance\n",
    "cc_sampler = ClusterCentroids(random_state=1)\n",
    "\n",
    "# Fit the training data to the cluster centroids model\n",
    "X_resampled, y_resampled = cc_sampler.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Count distinct values for the resampled target data\n",
    "y_resampled.value_counts()\n",
    "\n",
    "# Instantiate a new RandomForestClassier model\n",
    "cc_model = RandomForestClassifier()\n",
    "\n",
    "# Fit the resampled data the new model\n",
    "cc_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Predict labels for resampled testing features\n",
    "cc_y_pred = cc_model.predict(X_test_scaled)\n",
    "\n",
    "# Print classification reports\n",
    "print(f\"Classification Report - Original Data\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"---------\")\n",
    "print(f\"Classification Report - Resampled Data - CentroidClusters\")\n",
    "print(classification_report(y_test, cc_y_pred))\n",
    "\n",
    "## SMOTE\n",
    "# Import SMOTE from imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Instantiate the SMOTE instance \n",
    "# Set the sampling_strategy parameter equal to auto\n",
    "smote_sampler = SMOTE(random_state=1, sampling_strategy='auto')\n",
    "\n",
    "# Fit the training data to the smote_sampler model\n",
    "X_resampled, y_resampled = smote_sampler.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Count distinct values for the resampled target data\n",
    "y_resampled.value_counts()\n",
    "\n",
    "# Instantiate a new RandomForestClassier model \n",
    "smote_model = RandomForestClassifier()\n",
    "\n",
    "# Fit the resampled data to the new model\n",
    "smote_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Predict labels for resampled testing features\n",
    "smote_y_pred = smote_model.predict(X_test_scaled)\n",
    "\n",
    "# Print classification reports\n",
    "print(f\"Classification Report - Original Data\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"---------\")\n",
    "print(f\"Classification Report - Resampled Data - SMOTE\")\n",
    "print(classification_report(y_test, smote_y_pred))\n",
    "\n",
    "## SMOTEENN\n",
    "# Import SMOTEEN from imblearn\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "# Instantiate the SMOTEENN instance\n",
    "smote_enn = SMOTEENN(random_state=1)\n",
    "\n",
    "# Fit the model to the training data\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Instantiate a new RandomForestClassier model\n",
    "smoteenn_model = RandomForestClassifier()\n",
    "\n",
    "# Fit the resampled data the new model\n",
    "smoteenn_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Predict labels for resampled testing features\n",
    "smoteenn_y_pred = smoteenn_model.predict(X_test_scaled)\n",
    "\n",
    "# Print classification reports\n",
    "print(f\"Classification Report - Original Data\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"---------\")\n",
    "print(f\"Classification Report - Resampled Data - SMOTEENN\")\n",
    "print(classification_report(y_test, smoteenn_y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
